# ITalk
Android app created for the CopenHacks2019, Denmark  
Made of CNN based on the YOLOv3 and Tensorflow. It allows us to detect items using the camera in real time and translate their names to different languages. Microsoft Cognitive Services were used to convert text into natural-sounding speech and Google translation API to translate it to various languages.  
The app contains a Main Menu where the user can select a language and open the camera. After that the network starts detection and pronounciation of the names of the objects.  
Technologies: Tensorflow, MicrosoftAzure Cognitive Services, GoogletranslationAPI, Java, Python
